{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse as ap\n",
    "import cv2\n",
    "import imutils \n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from scipy.cluster.vq import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = ['Bedroom', 'Coast', 'Forest', 'Highway', 'Industrial', 'InsideCity', 'Kitchen', 'LivingRoom', 'Mountain', 'Office','OpenCountry', 'Store', 'Street', 'Suburb', 'TallBuilding']\n",
    "save_dir = \"result/Task2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect train data feature\n",
    "\n",
    "des_list = []\n",
    "path = \"train/**/*\"\n",
    "\n",
    "t1 = time.time()\n",
    "files = glob.glob(path)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "for File in files:\n",
    "    #print(File)\n",
    "    im = cv2.imread(File)\n",
    "    #print(im)\n",
    "    #im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    #im = cv2.normalize(im, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    #im = cv2.resize(im, (200,200), interpolation = cv2.INTER_CUBIC)\n",
    "    kp1, des1 = sift.detectAndCompute(im,None)\n",
    "    des_list.append((File, des1))\n",
    "    #print(len(des_list))\n",
    "    \n",
    "des_list_0 = des_list[0]\n",
    "descriptors = des_list_0[1]\n",
    "\n",
    "for image_path, descriptor in des_list[1:]:\n",
    "    if descriptor is None:\n",
    "        print(0)\n",
    "        continue\n",
    "    #print(descriptor.shape)\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "    #print(descriptor.shape)\n",
    "#print(descriptors)\n",
    "t2 = time.time()\n",
    "print(\"Detect train data time: \", t2-t1)\n",
    "print(descriptors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect test data feature\n",
    "\n",
    "test_list = []\n",
    "path = \"test/**/*\"\n",
    "\n",
    "t1 = time.time()\n",
    "files = glob.glob(path)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "for File in files:\n",
    "    im = cv2.imread(File)\n",
    "    #im = cv2.normalize(im, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    #im = cv2.resize(im, (200,200), interpolation = cv2.INTER_CUBIC)\n",
    "    kp1, des1 = sift.detectAndCompute(im,None)\n",
    "    test_list.append((File, des1))\n",
    "    #print(des1)\n",
    "    \n",
    "t2 = time.time()\n",
    "print(\"Detect test data time: \", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K means for all feature\n",
    "# Perform k-means clustering\n",
    "t1 = time.time()\n",
    "k = 300\n",
    "voc, variance = kmeans(descriptors, k, 1) \n",
    "t2 = time.time()\n",
    "print(\"time:\", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the histogram of features\n",
    "im_features = np.zeros((1500, k), \"float32\")\n",
    "for i in range(1500):\n",
    "    if des_list[i][1] is None:\n",
    "        continue\n",
    "    words, distance = vq(des_list[i][1],voc)\n",
    "\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "    #im_features[i] /= np.sum(im_features[i])\n",
    "    #im_features[i] /= np.sqrt(np.sum(im_features[i]**2))\n",
    "    im_features[i] = (im_features[i] - np.mean(im_features[i])) / np.std(im_features[i])\n",
    "    \n",
    "print(im_features)\n",
    "true_y=im_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of features based on K means center for each testing image\n",
    "# Calculate the histogram of features\n",
    "test_features = np.zeros((150, k), \"float32\")\n",
    "for i in range(150):\n",
    "    if test_list[i][1] is None:\n",
    "        continue\n",
    "    words, distance = vq(test_list[i][1],voc)\n",
    "    \n",
    "    for w in words:\n",
    "        test_features[i][w] += 1\n",
    "    #test_features[i] /= np.sum(test_features[i])\n",
    "    #test_features[i] /= np.sqrt(np.sum(test_features[i]**2))\n",
    "    test_features[i] = (test_features[i] - np.mean(test_features[i])) / np.std(test_features[i])\n",
    "\n",
    "print(test_features)\n",
    "pred_y=test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classifier\n",
    "\n",
    "def Euclidian(a, b):\n",
    "    return np.sqrt(np.sum((a-b)**2))\n",
    "    #return np.linalg.norm(a-b)\n",
    "\n",
    "def KNN(test, center, K):\n",
    "    dtype = [('dis', float), ('idx', int)]\n",
    "    distance = np.array([(Euclidian(test, center[i]),  i) for i in range(len(center))], dtype=dtype)\n",
    "    #print (distance)\n",
    "    newdistance = np.sort(distance, order='dis')\n",
    "    #print (newdistance)\n",
    "    \n",
    "    class_count = np.zeros(15)\n",
    "    for i in range(K):\n",
    "        _, idx = newdistance[i]\n",
    "        class_count[idx//100] += 1\n",
    "        \n",
    "    #print (class_count)\n",
    "    #print (np.argmax(class_count))\n",
    "    return np.argmax(class_count)\n",
    "    \n",
    "minIdx = 0\n",
    "count = 0.\n",
    "total = 0.\n",
    "\n",
    "for k in range(0,100,5):\n",
    "    total = 0.\n",
    "    for i in range(15):\n",
    "        count = 0.\n",
    "        for j in range(10):       \n",
    "            minIdx = KNN(test_features[i*10+j], im_features, k)\n",
    "            #print(minIdx)\n",
    "            \n",
    "            if minIdx == i:\n",
    "                count += 1.\n",
    "        #print(i,count/10.)\n",
    "        total += count\n",
    "    print(k, \"total:\", total/150.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(true_y, pred_y, save_dir):\n",
    "    sns.heatmap(confusion_matrix(true_y, pred_y, labels=label_type, normalize='true'),xticklabels=label_type,yticklabels=label_type)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_res(true_y, pred_y, save_dir='res'):\n",
    "    \n",
    "    def unique_by_key(elements, key=None):\n",
    "        if key is None:\n",
    "            # no key: the whole element must be unique\n",
    "            key = lambda e: e\n",
    "        return list({key(el): el for el in elements}.values())\n",
    "    \n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    train_dict = {}\n",
    "    test_dict = {}\n",
    "\n",
    "    for index, label in enumerate(label_type):\n",
    "        training_imgs = glob.glob('train/{}/*.jpg'.format(label))\n",
    "        testing_imgs = glob.glob('test/{}/*.jpg'.format(label))\n",
    "        for fname in training_imgs:\n",
    "            img = cv2.imread(fname)\n",
    "            train.append(img)\n",
    "            if label not in train_dict:\n",
    "                train_dict[label] = img\n",
    "\n",
    "        for fname in testing_imgs:\n",
    "            img = cv2.imread(fname)\n",
    "            test.append(img)\n",
    "            if label not in test_dict:\n",
    "                test_dict[label] = img\n",
    "                \n",
    "    false_negative = {k:[] for k in label_type}\n",
    "    false_positive = {k:[] for k in label_type}\n",
    "    true_positive = {k:[] for k in label_type} \n",
    "    \n",
    "    for idx in range(len(true_y)):\n",
    "        if true_y[idx] != pred_y[idx]:\n",
    "            false_negative[true_y[idx]].append((idx,pred_y[idx]))\n",
    "            false_positive[pred_y[idx]].append((idx,true_y[idx]))   \n",
    "        else:\n",
    "            true_positive[true_y[idx]].append(idx)\n",
    "            \n",
    "    for cat in false_negative:\n",
    "        false_negative[cat]=unique_by_key(false_negative[cat], key=itemgetter(1))\n",
    "\n",
    "    for cat in false_positive:\n",
    "        false_negative[cat]=unique_by_key(false_negative[cat], key=itemgetter(1))\n",
    "        \n",
    "    fig, axes = plt.subplots(nrows=16, ncols=5, figsize=(12, 30))\n",
    "\n",
    "    axes[0][0].axis('off')\n",
    "    \n",
    "    for idx, cat in enumerate(label_type):\n",
    "        \n",
    "        axes[idx+1][1].axis('off')\n",
    "        axes[idx+1][1].imshow(train_dict[cat])\n",
    "        \n",
    "        axes[idx+1][2].axis('off')\n",
    "        if len(true_positive[cat])!=0:\n",
    "            axes[idx+1][2].imshow(test[true_positive[cat][0]])\n",
    "        \n",
    "        axes[idx+1][3].axis('off')\n",
    "        if len(false_positive[cat])!=0:\n",
    "            axes[idx+1][3].set_title(false_positive[cat][0][1])\n",
    "            axes[idx+1][3].imshow(test[false_positive[cat][0][0]])\n",
    "            \n",
    "        axes[idx+1][4].axis('off')\n",
    "        axes[idx+1][4].patch.set_facecolor('xkcd:mint green')\n",
    "        if len(false_negative[cat])!=0:\n",
    "            axes[idx+1][4].set_title(false_negative[cat][0][1])\n",
    "            axes[idx+1][4].imshow(test[false_negative[cat][0][0]])\n",
    "            \n",
    "    for ax, row in zip(axes[1:,0], label_type):\n",
    "        ax.axis('off')\n",
    "        ax.set_title(row, rotation=0, size='large',fontweight='bold',loc='right')\n",
    "        \n",
    "    for ax, col in zip(axes[0][1:], [\"Sample training images\",\"Sample true positives\",\"False positives with \\ntrue label\",'False negatives with \\nwrong predicted label']):\n",
    "        ax.axis('off')\n",
    "        ax.set_title(col, rotation=0, size='large',fontweight='bold',y=-0.01)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.savefig(save_dir)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(true_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(des_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(minIdx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import get_data, plot_heatmap, plot_res\n",
    "minIdx = 0\n",
    "count = 0.\n",
    "best = 0\n",
    "test_y = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "          3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
    "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
    "          5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
    "          6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
    "          7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
    "          8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
    "          9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "          10, 10, 10, 10, 10, 10, 10, 10, 10, 10, \n",
    "          11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
    "          12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
    "          13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
    "          14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
    "for k in range(0,100,5):\n",
    "    pred = []\n",
    "    total = 0.\n",
    "    for i in range(15):\n",
    "        count = 0.\n",
    "        for j in range(10):       \n",
    "            minIdx = KNN(test_features[i*10+j], im_features, k)\n",
    "            pred.append(minIdx)\n",
    "            if minIdx == i:\n",
    "                count += 1.\n",
    "        total += count\n",
    "    if total>best:\n",
    "        y_pred = pred\n",
    "    print(k, \"total:\", total/150.)\n",
    "    \n",
    "y_pred = np.array(y_pred)\n",
    "y_true = test_y\n",
    "#y_true = list(test_y.astype(int))\n",
    "\n",
    "\n",
    "plot_heatmap(y_true,y_pred,'./result/1')\n",
    "plot_res(y_true,y_pred,'./result/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
