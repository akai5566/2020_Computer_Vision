{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect train data time:  132.63566255569458\n",
      "Detect test data time:  2.100090503692627\n",
      "Perform k-means clustering time:  272.27280044555664\n"
     ]
    }
   ],
   "source": [
    "#/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Bag of SIFT representation + nearest neighbor classifier\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse as ap\n",
    "import cv2\n",
    "import imutils \n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from scipy.cluster.vq import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from utilities import get_data, plot_heatmap, plot_res\n",
    "\n",
    "label_type = ['Bedroom', 'Coast', 'Forest', 'Highway', 'Industrial', 'InsideCity', 'Kitchen', 'LivingRoom', 'Mountain', 'Office','OpenCountry', 'Store', 'Street', 'Suburb', 'TallBuilding']\n",
    "save_dir = \"result/Task2\"\n",
    "\n",
    "\n",
    "# Detect train data feature\n",
    "\n",
    "des_list = []\n",
    "path = \"train/**/*\"\n",
    "\n",
    "t1 = time.time()\n",
    "files = glob.glob(path)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "for File in files:\n",
    "    #print(File)\n",
    "    im = cv2.imread(File)\n",
    "    #print(im)\n",
    "    #im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    #im = cv2.normalize(im, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    #im = cv2.resize(im, (200,200), interpolation = cv2.INTER_CUBIC)\n",
    "    kp1, des1 = sift.detectAndCompute(im,None)\n",
    "    des_list.append((File, des1))\n",
    "    #print(len(des_list))\n",
    "    \n",
    "des_list_0 = des_list[0]\n",
    "descriptors = des_list_0[1]\n",
    "\n",
    "for image_path, descriptor in des_list[1:]:\n",
    "    if descriptor is None:\n",
    "        print(0)\n",
    "        continue\n",
    "    #print(descriptor.shape)\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "    #print(descriptor.shape)\n",
    "#print(descriptors)\n",
    "t2 = time.time()\n",
    "print(\"Detect train data time: \", t2-t1)\n",
    "\n",
    "#print(descriptors.shape)\n",
    "\n",
    "\n",
    "# Detect test data feature\n",
    "\n",
    "test_list = []\n",
    "path = \"test/**/*\"\n",
    "\n",
    "t1 = time.time()\n",
    "files = glob.glob(path)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "for File in files:\n",
    "    im = cv2.imread(File)\n",
    "    #im = cv2.normalize(im, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    #im = cv2.resize(im, (200,200), interpolation = cv2.INTER_CUBIC)\n",
    "    kp1, des1 = sift.detectAndCompute(im,None)\n",
    "    test_list.append((File, des1))\n",
    "    #print(des1)\n",
    "    \n",
    "t2 = time.time()\n",
    "print(\"Detect test data time: \", t2-t1)\n",
    "\n",
    "\n",
    "# K means for all feature\n",
    "# Perform k-means clustering\n",
    "t1 = time.time()\n",
    "k = 295\n",
    "voc, variance = kmeans(descriptors, k, 1) \n",
    "t2 = time.time()\n",
    "print(\"Perform k-means clustering time: \", t2-t1)\n",
    "\n",
    "\n",
    "# ## Enlarge feature number\n",
    "\n",
    "des_list = []\n",
    "path = \"train/**/*\"\n",
    "\n",
    "t1 = time.time()\n",
    "files = glob.glob(path)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "for File in files:\n",
    "    im = cv2.imread(File)\n",
    "    im = cv2.resize(im, (600,600), interpolation = cv2.INTER_CUBIC)\n",
    "    kp1, des1 = sift.detectAndCompute(im,None)\n",
    "    des_list.append((File, des1))\n",
    "    #print(len(des_list))\n",
    "\n",
    "descriptors = des_list[0][1]\n",
    "for image_path, descriptor in des_list[1:]:\n",
    "    if descriptor is None:\n",
    "        print(0)\n",
    "        continue\n",
    "    #print(descriptor.shape)\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "    #print(descriptor.shape)\n",
    "#print(descriptors)\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Enlarge feature training data time:\", t2-t1)\n",
    "\n",
    "\n",
    "test_list = []\n",
    "path = \"test/**/*\"\n",
    "\n",
    "t1 = time.time()\n",
    "files = glob.glob(path)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "for File in files:\n",
    "    im = cv2.imread(File)\n",
    "    im = cv2.resize(im, (1000,1000), interpolation = cv2.INTER_CUBIC)\n",
    "    kp1, des1 = sift.detectAndCompute(im,None)\n",
    "    test_list.append((File, des1))\n",
    "    #print(des1)\n",
    "    \n",
    "t2 = time.time()\n",
    "print(\"Enlarge feature testing data time:\", t2-t1)\n",
    "\n",
    "#Histogram of features based on K means center for each training image\n",
    "# Calculate the histogram of features\n",
    "\n",
    "im_features = np.zeros((1500, k), \"float32\")\n",
    "for i in range(1500):\n",
    "    if des_list[i][1] is None:\n",
    "        continue\n",
    "    words, distance = vq(des_list[i][1],voc)\n",
    "\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "    #im_features[i] /= np.sum(im_features[i])\n",
    "    #im_features[i] /= np.sqrt(np.sum(im_features[i]**2))\n",
    "    im_features[i] = (im_features[i] - np.mean(im_features[i])) / np.std(im_features[i])\n",
    "\n",
    "print(\"img feature: \", im_features)\n",
    "true_y=im_features\n",
    "\n",
    "# Histogram of features based on K means center for each testing image\n",
    "# Calculate the histogram of features\n",
    "\n",
    "test_features = np.zeros((150, k), \"float32\")\n",
    "for i in range(150):\n",
    "    if test_list[i][1] is None:\n",
    "        continue\n",
    "    words, distance = vq(test_list[i][1],voc)\n",
    "    \n",
    "    for w in words:\n",
    "        test_features[i][w] += 1\n",
    "    #test_features[i] /= np.sum(test_features[i])\n",
    "    #test_features[i] /= np.sqrt(np.sum(test_features[i]**2))\n",
    "    test_features[i] = (test_features[i] - np.mean(test_features[i])) / np.std(test_features[i])\n",
    "\n",
    "print(\"test feature: \", test_features)\n",
    "pred_y=test_features\n",
    "\n",
    "# KNN classifier\n",
    "\n",
    "def Euclidian(a, b):\n",
    "    return np.sqrt(np.sum((a-b)**2))\n",
    "    #return np.linalg.norm(a-b)\n",
    "\n",
    "def KNN(test, center, K):\n",
    "    dtype = [('dis', float), ('idx', int)]\n",
    "    distance = np.array([(Euclidian(test, center[i]),  i) for i in range(len(center))], dtype=dtype)\n",
    "    #print (distance)\n",
    "    newdistance = np.sort(distance, order='dis')\n",
    "    #print (newdistance)\n",
    "    \n",
    "    class_count = np.zeros(15)\n",
    "    for i in range(K):\n",
    "        _, idx = newdistance[i]\n",
    "        class_count[idx//100] += 1\n",
    "        \n",
    "    #print (class_count)\n",
    "    #print (np.argmax(class_count))\n",
    "    return np.argmax(class_count)\n",
    "    \n",
    "minIdx = 0\n",
    "count = 0.\n",
    "total = 0.\n",
    "best = 0\n",
    "\n",
    "test_y = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "          3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
    "          4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
    "          5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
    "          6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
    "          7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
    "          8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
    "          9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "          10, 10, 10, 10, 10, 10, 10, 10, 10, 10, \n",
    "          11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
    "          12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
    "          13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
    "          14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
    "\n",
    "for k in range(0,100,5):\n",
    "    pred = []\n",
    "    total = 0.\n",
    "    for i in range(15):\n",
    "        count = 0.\n",
    "        for j in range(10):       \n",
    "            minIdx = KNN(test_features[i*10+j], im_features, k)\n",
    "            pred.append(minIdx)\n",
    "            if minIdx == i:\n",
    "                count += 1.\n",
    "        total += count\n",
    "    if total>best:\n",
    "        y_pred = pred\n",
    "    print(k, \"total:\", total/150.)\n",
    "    \n",
    "y_pred = np.array(y_pred)\n",
    "y_true = test_y\n",
    "\n",
    "plot_heatmap(y_true,y_pred,'./result/1')\n",
    "plot_res(y_true,y_pred,'./result/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
